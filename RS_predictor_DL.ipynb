{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "True\n",
      "True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS is available to use GPU from mac\n",
    "print(torch.__version__)\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_cleaned.csv')\n",
    "test = pd.read_csv('test_cleaned.csv')\n",
    "\n",
    "train = train.astype('float32')\n",
    "test = test.astype('float32')\n",
    "\n",
    "X_train = torch.tensor(train.drop('y', axis=1).values, dtype=torch.float32)\n",
    "y_train = torch.tensor(train['y'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8000, 54]) torch.Size([8000])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple FNN with regularization layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealEstateNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RealEstateNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 54),\n",
    "            nn.BatchNorm1d(54),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(54, 48),\n",
    "            nn.BatchNorm1d(48),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(48, 24),\n",
    "            nn.BatchNorm1d(24),\n",
    "            nn.SiLU(),\n",
    "\n",
    "            nn.Linear(24, 12),\n",
    "            nn.BatchNorm1d(12),\n",
    "            nn.SiLU(),\n",
    "\n",
    "            nn.Linear(12, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fit(model, dataloader, criterion, optimizer, num_epochs=10, device=device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader):.4f}\")\n",
    "    print('model trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 54\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 40\n",
    "batch_size = 16\n",
    "\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RealEstateNN(input_size).to(device)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DeepLearning/lib/python3.12/site-packages/torch/nn/modules/loss.py:128: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 540267.0848\n",
      "Epoch [2/40], Loss: 538447.0519\n",
      "Epoch [3/40], Loss: 535009.0884\n",
      "Epoch [4/40], Loss: 530196.7386\n",
      "Epoch [5/40], Loss: 524190.8332\n",
      "Epoch [6/40], Loss: 517120.7262\n",
      "Epoch [7/40], Loss: 509046.9859\n",
      "Epoch [8/40], Loss: 500033.6099\n",
      "Epoch [9/40], Loss: 490204.9403\n",
      "Epoch [10/40], Loss: 479508.3990\n",
      "Epoch [11/40], Loss: 468013.8521\n",
      "Epoch [12/40], Loss: 455715.9816\n",
      "Epoch [13/40], Loss: 442632.8937\n",
      "Epoch [14/40], Loss: 429010.2549\n",
      "Epoch [15/40], Loss: 415049.5221\n",
      "Epoch [16/40], Loss: 400491.6928\n",
      "Epoch [17/40], Loss: 386373.2968\n",
      "Epoch [18/40], Loss: 372207.5634\n",
      "Epoch [19/40], Loss: 358933.6702\n",
      "Epoch [20/40], Loss: 345528.7452\n",
      "Epoch [21/40], Loss: 333004.7159\n",
      "Epoch [22/40], Loss: 321595.0877\n",
      "Epoch [23/40], Loss: 311551.7176\n",
      "Epoch [24/40], Loss: 302486.3279\n",
      "Epoch [25/40], Loss: 294758.7840\n",
      "Epoch [26/40], Loss: 288107.7563\n",
      "Epoch [27/40], Loss: 282712.9626\n",
      "Epoch [28/40], Loss: 278171.8748\n",
      "Epoch [29/40], Loss: 274920.3875\n",
      "Epoch [30/40], Loss: 272714.9997\n",
      "Epoch [31/40], Loss: 271048.5912\n",
      "Epoch [32/40], Loss: 270006.5920\n",
      "Epoch [33/40], Loss: 269274.0664\n",
      "Epoch [34/40], Loss: 268763.6060\n",
      "Epoch [35/40], Loss: 268389.4958\n",
      "Epoch [36/40], Loss: 268302.2407\n",
      "Epoch [37/40], Loss: 268088.0034\n",
      "Epoch [38/40], Loss: 268004.9966\n",
      "Epoch [39/40], Loss: 267875.1201\n",
      "Epoch [40/40], Loss: 267873.9832\n",
      "model trained!\n"
     ]
    }
   ],
   "source": [
    "train_fit(model, dataloader, criterion, optimizer, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
